{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 차원 축소 (Dimension Reduction)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원의 저주 (Curse of Dimensionality)\n",
    "- 관측치보다 변수의 수가 더 많은 경우\n",
    "- 예. 데이터 양은 100, 데이터 차원은 500\n",
    "- 데이터 학습을 위해 차원이 증가하면서 학습데이터수가 차원수보다 적어져(sparse) 성능이 저하되는 현상\n",
    "- 빈공간이 많이 생기는 문제\n",
    "- 데이터의 차원이 늘어날수록 해당 공간의 크기가 기하급수적으로 증가하고 데이터의 밀도는 희박해지기 때문에 데이터 분석에 필요한 데이터의 수는 기하급수적으로 증가하게 됨\n",
    "- $ 데이터밀도 = 데이터 개수^{1 \\over 차원의 수} $\n",
    "    - 예. 10차원 500개 데이터의 밀도 : $ 500^{1 \\over 10} = 1.86 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 차원이 증가할수록 데이터 포인트 간의 거리가 기하급수적으로 멀어지게 되고 희소(sparse)한 구조를 가지게 됨\n",
    "- 수백 개 이상의 피처로 구성된 데이터 세트의 경우\n",
    "    - 상대적으로 적은 차원에서 학습된 모델보다 예측 신뢰도가 떨어짐\n",
    "- 또한 피처가 많을 경우 개별 피처 간의 상관관계가 높을 가능성이 큼\n",
    "    - 선형 회귀와 같은 선형 모델에서는 입력 변수 간의 상관관계가 높을 경우 이로 인한 다중 공선성 문제로 모델의 예측 성능 저하"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 축소 (Dimension Reduction)\n",
    "- 매우 많은 특성변수로 구성된 다차원 데이터 세트의 차원을 축소해 새로운 차원의 데이터 세트를 생성하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 차원 축소 이점\n",
    "- 많은 다차원의 특성변수를 차원 축소해 피처 수를 줄이면 더 직관적으로 데이터 해석 가능\n",
    "- 수십 개 이상의 피처가 있는 데이터는 시각적으로 표현 시 데이터의 특성 파악 불가능\n",
    "- 3차원 이하의 차원 축소를 통해서 시각적으로 데이터를 압축해서 표현 가능\n",
    "- 또한 학습 데이터의 크기가 줄어 들어서 학습에 필요한 처리 능력도 줄일 수 있음"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 축소 방법\n",
    "- 피처 선택(Feature Selection)\n",
    "- 피처 추출(Fetures Extraction)\n",
    "\n",
    "#### 피처 선택(Feature Selection)\n",
    "- 특정 피처에 종속성이 강한 불필요한 피처는 제거하고 데이터의 특징을 잘 나타내는 주요 피처만 선택하는 것\n",
    "- 불필요한 변수 제거\n",
    "- Filtering : 목표변수를 잘 설명할 수 있는 변수만을 선택하는 방식\n",
    "- Wrapper : 학습알고리즘을 이용하여 다양한 변수 조합 중 모델 성능이 좋은 변수 조합을 찾음(backward selection, forward selection, stepwise selection)\n",
    "- Embedded : 학습알고리즘 자체에 feature selection을 포함하는 경우\n",
    "\n",
    "\n",
    "#### 피처 추출(Fetures Extraction)\n",
    "- 기존 피처를 저차원의 중요 피처로 압축해서 추출하는 것\n",
    "- 새롭게 추출된 중요 특성은 기존의 피처가 압축된 것이므로 기존의 피처와는 완전히 다른 값이 됨\n",
    "- 기존 피처를 단순 압축이 아니고 피처를 함축적으로 더 잘 설명할 수 있는 또 다른 공간으로 매핑해 추출하는 것\n",
    "- PCA, SVD, LDA, NMF(Non-negative matrix factorization)\n",
    "\n",
    "\n",
    "예: 학생 평가 요소\n",
    "- 모의고사 성적, 종합 내신성적, 수능성적, 봉사활동, 대외활동, 학교 내외 수상경력 등\n",
    "- 함축적 요약 특성 으로 추출 : 학업 성취도, 커뮤니케이션 능력, 문제 해결력\n",
    "- 함축적인 특성 추출 : 기존 피처가 전혀 인지하기 어려웠던 잠재적인 요소를 추출하는 것을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 차원 축소의 중요 의미\n",
    "- 차원 축소를 통해 좀 더 데이터를 잘 설명할 수 있는 잠재적인 요소를 추출하는 데 있음\n",
    "- PCA, SVD, NMF는 잠재적인 요소를 찾는 대표적인 차원 축소 알고리즘\n",
    "- 매우 많은 차원을 가지고 있는 이미지나 텍스트에서 차원 축소를 통해 잠재적인 의미를 찾아주는 데 잘 활용되고 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이미지 데이터 영역에서의 차원 축소 알고리즘\n",
    "- 많은 픽셀로 이루어진 이미지 데이터에서 잠재된 특성을 피처로 도출해 함축적 형태의 이미지 변환과 압축 수행\n",
    "- 변환된 이미지는 원본 이미지보다 훨씬 적은 차원이기 때문에 이미지 분류 등의 분류 수행 시에 과적합 영향력이 작아져서 오히려 원본 데이터로 예측하는 것보다 예측 성능을 더 끌어 올릴 수 있음\n",
    "- 이미지 자체가 가지고 있는 차원의 수가 너무 크기 때문에 비슷한 이미지라도 적은 픽셀의 차이가 잘못된 예측으로 이어질 수 있기 때문에 이 경우 함축적으로 차원을 축소하는 것이 예측 성능에 훨씬 도움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트 영역에서의 차원 축소 알고리즘\n",
    "- 텍스트 문서의 숨겨진 의미를 추출하는 것\n",
    "- 문서는 많은 단어로 구성되어 있는데 문서를 작성하는 사람은 어떤 의미나 의도를 가지고 문서를 작성하면서 단어 사용\n",
    "- 일반적으로 사람의 경우 문서를 읽으면서 문서가의 의미나 의도를 쉽게 인지 가능\n",
    "- 차원 축소 알고리즘은 문서 내 단어들의 구성에서 숨겨져 있는 시맨틱의미나 토픽(topic)을 잠재 요소로 간주하고 찾아 낼 수 있음\n",
    "- SVD와 NMF는 시맨틱 토픽 모델링을 위한 기반 알고리즘으로 사용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 대표적인 차원 축소 알고리즘\n",
    "- PCA\n",
    "- FA(Factor Analysis)\n",
    "- LDA\n",
    "- SVD\n",
    "- NMF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA\n",
    "- 상관이 있는 변수들로 구성된 자료들을 서로 독립인 변수(주성분)으로 변환하는 방법\n",
    "- 관측된 변수들의 선형결합(변수간의 중요성이 있음)\n",
    "- 공분산 행렬에서 고유벡터/고유값을 구하고 분산이 큰 방향을 가진 고유벡터에 입력데이터를 선형변환(고유값분해)\n",
    "- 입력 데이터의 변동성이 가장 큰 축을 구하고, 다시 이 축에 직각인 축을 반복적으로 축소하려는 차원 개수만큼 구한 뒤 입력 데이터를 이 축들에 투영해 차원을 축소하는 방식\n",
    "- 이를 위해 입력 데이터의 공분산 행렬을 기반으로 고유 벡터(Eigenvector)를 생성하고 이렇게 구한 고유 벡터에 입력 데이터를 선형 변환하는 방식"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FA(Factor Analysis)\n",
    "- 공통요인들의 선형결합을 통해 소수의 새로운 변수를 생성\n",
    "- 변수간의 순서가 없음. 변수들은 기본적으로 대등한 관계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA(Linear Discriminant Analysis)\n",
    "- 선형 판별 분석법\n",
    "- PCA와 유사하게 입력 데이터 세트를 저차원 공간에 투영해 차원을 축소하는 기법\n",
    "- 중요한 차이는 지도학습의 분류에서 사용하기 쉽도록  개별 클래스를 분별할 수 있는 기준을 최대한 유지하면서 차원 축소\n",
    "- PCA는 입력 데이터의 변동성의 가장 큰 축을 찾지만\n",
    "- LDA는 입력 데이터의 결정 값 클래스를 최대한으로 분리할 수 있는 축을 찾음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVD와 NMF\n",
    "- 매우 많은 피처 데이터를 가진 고차원 행렬을 두 개의 저차원 행렬로 분리하는 행렬 분해 기법\n",
    "- 행렬 분해를 수행하면서 원본 행렬에서 잠재된 요소를 추출\n",
    "- 토픽 모델링이나 추천 시스템에서 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVD(Singula Value Decomposition)\n",
    "- PCA와 유사한 행렬 분해 기법 이용\n",
    "- PCA의 경우 정방행렬만을 고유벡터로 분해\n",
    "- SVD는 정방행렬이 아닌 m행n열의 다양한 행렬에 대한 고유값 분해 일반화 버전\n",
    "- 자료행렬의 특성값분해로 주성분 도출 가능\n",
    "- 데이터 용량을 줄이거나 압축을 위해 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NMF(Non-Negative Matrix Factorization)\n",
    "- 원본 행렬 내의 모든 원소 값이 모두 양수(0 이상)라는 게 보장되면\n",
    "- 좀더 간단하게 두 개의 기반 양수 행렬로 분해될 수 있는 기법 지칭"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA와 SVD \n",
    "- 많은 차원을 가지는 이미지나 텍스트에서 활발하게 사용됨"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
